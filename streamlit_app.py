import streamlit as st
from openai import OpenAI
from gtts import gTTS
from io import BytesIO
from streamlit_webrtc import webrtc_streamer
import tempfile

# Initialize OpenAI client
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# App title
st.title("рж╕рзНржмрж╛рж╕рзНржерзНржп ржЙржкрж╕рж░рзНржЧ рж╕рж╣ржХрж╛рж░рзА (ржорж╛рж▓рзНржЯрж┐ржорзЛржбрж╛рж▓)")

# Mode selector
mode = st.radio("ржЖржкржирж┐ ржХрзАржнрж╛ржмрзЗ ржХржерж╛ ржмрж▓рждрзЗ ржЪрж╛ржи?", [
    "тЬНя╕П Text тЮЭ Text",
    "тЬНя╕П Text тЮЭ ЁЯОз Audio",
    "ЁЯОЩя╕П Audio тЮЭ Text",
    "ЁЯОЩя╕П Audio тЮЭ ЁЯОз Audio"
])

# Session state init
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "system",
            "content": (
                "рждрзБржорж┐ ржПржХржЬржи рж╕рзНржмрж╛рж╕рзНржерзНржп рж╕рж╣ржХрж╛рж░рзАред ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзА ржпрзЗржХрзЛржирзЛ ржнрж╛рж╖рж╛ржпрж╝ рж▓рж┐ржЦрждрзЗ ржмрж╛ ржмрж▓рждрзЗ ржкрж╛рж░рзЗ, "
                "ржХрж┐ржирзНрждрзБ рждрзБржорж┐ рж╕ржмрж╕ржоржпрж╝ ржмрж╛ржВрж▓рж╛ ржнрж╛рж╖рж╛ржпрж╝ рж╕рж╣ржЬ ржУ рж╕рж╛ржзрж╛рж░ржг рж╕рзНржмрж╛рж╕рзНржерзНржп ржкрж░рж╛ржорж░рзНрж╢ ржжрзЗржмрзЗред "
                "рждрзБржорж┐ ржбрж╛ржХрзНрждрж╛рж░ ржиржУ, рждрж╛ржЗ ржЪрж┐ржХрж┐рзОрж╕рж╛ ржмрж╛ ржУрж╖рзБржзрзЗрж░ ржирж╛ржо ржжрж┐ржУ ржирж╛ред"
            )
        }
    ]

# Show previous messages (skip system)
for msg in st.session_state.messages[1:]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Text-to-speech function
def speak_bangla(text):
    tts = gTTS(text=text, lang="bn")
    mp3_fp = BytesIO()
    tts.write_to_fp(mp3_fp)
    mp3_fp.seek(0)
    return mp3_fp

# Get assistant response
def get_response(user_text):
    prompt = (
        f"ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзА рж▓рж┐ржЦрзЗржЫрзЗ ржмрж╛ ржмрж▓рзЗржЫрзЗ: \"{user_text}\"ред "
        "ржЙржкрж╕рж░рзНржЧ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг ржХрж░рзЗ ржмрж╛ржВрж▓рж╛ржпрж╝ рж╕рж╣ржЬ ржнрж╛рж╖рж╛ржпрж╝ рж╕рж╛ржзрж╛рж░ржг рж╕рзНржмрж╛рж╕рзНржерзНржп ржкрж░рж╛ржорж░рзНрж╢ ржжрж╛ржУред "
        "ржбрж╛ржХрзНрждрж╛рж░рзЗрж░ ржкрж░рж╛ржорж░рзНрж╢ ржЫрж╛ржбрж╝рж╛ ржХрзЛржирзЛ ржЪрж┐ржХрж┐рзОрж╕рж╛ ржмрж╛ ржУрж╖рзБржзрзЗрж░ ржирж╛ржо ржжрж┐ржУ ржирж╛ред"
    )
    messages = st.session_state.messages + [{"role": "user", "content": user_text}, {"role": "user", "content": prompt}]
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages
    )
    return response.choices[0].message.content

# Handle input based on mode
user_input = None

if "Text" in mode:
    text = st.chat_input("ржЖржкржирж╛рж░ ржЙржкрж╕рж░рзНржЧ рж▓рж┐ржЦрзБржи...")
    if text:
        user_input = text

if "Audio" in mode:
    st.subheader("ЁЯОЩя╕П ржнржпрж╝рзЗрж╕ ржЗржиржкрзБржЯ (mp3/wav ржЖржкрж▓рзЛржб ржХрж░рзБржи)")
    audio = st.file_uploader("ржЖржкржирж╛рж░ ржнржпрж╝рзЗрж╕ рж░рзЗржХрж░рзНржб ржХрж░рзБржи", type=["mp3", "wav"])
    if audio:
        audio_bytes = audio.read()
        audio_file = BytesIO(audio_bytes)
        with st.spinner("ржнржпрж╝рзЗрж╕ ржкрзНрж░рж╕рзЗрж╕ ржХрж░рж╛ рж╣ржЪрзНржЫрзЗ..."):
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="text",
                language="bn"
            )
            st.success(f"ржЖржкржирж╛рж░ ржХржерж╛: {transcript}")
            user_input = transcript

# Process if we have any user input (text or audio)
if user_input:
    # Show user message
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # Get assistant response
    response = get_response(user_input)
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)

    # Play voice if mode says so
    if "Audio" in mode:
        st.subheader("ЁЯФК рж╕рж╣ржХрж╛рж░рзАрж░ ржЕржбрж┐ржУ ржЙрждрзНрждрж░")
        audio_response = speak_bangla(response)
        st.audio(audio_response, format="audio/mp3")
